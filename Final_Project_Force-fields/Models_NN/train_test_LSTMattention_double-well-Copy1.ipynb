{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0a5ace",
   "metadata": {},
   "source": [
    "### GENERATE TRAJECTORIES USING **DOUBLE-WELL POTENTIAL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18d2551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import Boltzmann as kB\n",
    "from numpy.random import randn as gauss\n",
    "from numpy.random import rand as uniform\n",
    "\n",
    "### Physical parameters \n",
    "R = 1e-7                                # Radius of the Brownian particle [m]\n",
    "eta = 0.001                             # Viscosity of the medium [kg m^-1 s^-1]\n",
    "T = 300                                 # Temperature [K]\n",
    "L0 = 2e-6                               # Reference distance from middle to one minimum [m]\n",
    "H0 = kB*300                             # Barrier height [Joule]\n",
    "gamma0 = 6 * np.pi * eta * R            # Reference friction coefficient [kg s^-1]\n",
    "\n",
    "### Simulation parameters\n",
    "N = 1000                   # Number of samples of the trajectory\n",
    "Dt = 1e-2                  # Timestep \n",
    "oversampling = 5           # Simulation oversampling\n",
    "offset = 1000              # Number of equilibration timesteps\n",
    "batch_size = 32            # Number of trajectories\n",
    "\n",
    "### Define functions to scale and rescale inputs\n",
    "scale_inputs = lambda x: x * 1e+6                    # Scales input trajectory to order 1\n",
    "rescale_inputs = lambda scaled_x: scaled_x * 1e-6    # Rescales input trajectory to physical units\n",
    "\n",
    "### Define function to scale and rescale targets\n",
    "scale_targets = lambda L, H: [L/L0 -1, np.log(H / H0)]                        # Scales targets to order 1\n",
    "rescale_targets = lambda scaled_L, scaled_H: [(1 + scaled_L)*L0*1e6, \n",
    "                                              np.exp(scaled_H) * H0/kB/300] # Inverse of targets_scaling\n",
    "\n",
    "def simulate_trajectory(batch_size=batch_size, \n",
    "                        T=T,\n",
    "                        H0=H0,\n",
    "                        L0=L0,\n",
    "                        gamma0=gamma0,\n",
    "                        N=N, \n",
    "                        Dt=Dt, \n",
    "                        oversampling=oversampling, \n",
    "                        offset=offset):#, \n",
    "                        #scale_inputs=scale_inputs, \n",
    "                        #scale_targets=scale_targets):\n",
    "    \n",
    "    ### Randomize trajectory parameters\n",
    "    L = L0 * (uniform(batch_size)+.5) \n",
    "    H = H0 * 10**(uniform(batch_size)*1.75 - .75)       # Generates random values for computing the stiffness\n",
    "    gamma = gamma0 * (uniform(batch_size) * .1 + .95)   # Marginal randomization of friction coefficient to tolarate small changes\n",
    "\n",
    "    ### Simulate\n",
    "    dt = Dt / oversampling                 # time step of the simulation\n",
    "    x = np.zeros((batch_size, N))          # initialization of the x array\n",
    "    k0 = 4*H/L**2 \n",
    "    k1 = 4*H/L**4\n",
    "    D = kB * T / gamma                     # diffusion coefficient\n",
    "    C1 = +k0 / gamma * dt\n",
    "    C2 = -k1 / gamma * dt                  # drift coefficient of the Langevin equation\n",
    "    C3 = np.sqrt(2 * D * dt)               # random walk coefficient of the Langevin equation\n",
    "    X = x[:, 0]\n",
    "    n = 0\n",
    "    \n",
    "    for t in range(offset):                      # Offset (for some prerun before running)\n",
    "        X = X + C1 * X + C2 * X**3 + C3 * gauss(batch_size)\n",
    "        #X = X - (2 * X**3) + (12 * X**2) - (18 * X) + 3 + (C3 * gauss(batch_size))\n",
    "        \n",
    "    for t in range(N * oversampling):            # Simulation                \n",
    "        X = X + C1 * X + C2 * X**3 + C3 * gauss(batch_size)\n",
    "        #X = X - (2 * X**3) + (12 * X**2) - (18 * X) + 3 + (C3 * gauss(batch_size))\n",
    "        if t % oversampling == 0:                # We save every oversampling^th values \n",
    "            x[:, n] = X \n",
    "            n += 1\n",
    "\n",
    "    inputs = scale_inputs(x)\n",
    "    targets = np.swapaxes(scale_targets(*[L, H]),0,1)\n",
    "    target_reals = np.swapaxes([L*1e6, H/kB/300],0,1)\n",
    "\n",
    "    return inputs, targets, target_reals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e8c03",
   "metadata": {},
   "source": [
    "##### TRAIN THE DEEP NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a563a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_learning_network(\n",
    "    network,\n",
    "    simulate_trajectory,\n",
    "    sample_sizes = (32, 128, 512),#(32, 128, 512, 2048),\n",
    "    iteration_numbers = (3001, 2001, 1001),#(1001, 2001, 3001),#(3001, 2001, 1001, 101),\n",
    "    verbose=.1):\n",
    "    \"\"\"Train a deep learning network.\n",
    "    \n",
    "    Input:\n",
    "    network: deep learning network\n",
    "    simulate_trajectory: trajectory generator function\n",
    "    sample_sizes: sizes of the batches of trajectories used in the training [tuple of positive integers]\n",
    "    iteration_numbers: numbers of batches used in the training [tuple of positive integers]\n",
    "    verbose: frequency of the update messages [number between 0 and 1]\n",
    "        \n",
    "    Output:\n",
    "    training_history: dictionary with training history\n",
    "    \"\"\"  \n",
    "    \n",
    "    import numpy as np\n",
    "    from time import time\n",
    "     \n",
    "    training_history = {}\n",
    "    training_history['Sample Size'] = []\n",
    "    training_history['Iteration Number'] = []\n",
    "    training_history['Iteration Time'] = []\n",
    "    training_history['MSE'] = []\n",
    "    training_history['MAE'] = []\n",
    "    \n",
    "    for sample_size, iteration_number in zip(sample_sizes, iteration_numbers):\n",
    "        for iteration in range(iteration_number):\n",
    "            \n",
    "            # measure initial time for iteration\n",
    "            initial_time = time()\n",
    "\n",
    "            # generate trajectories and targets\n",
    "            network_blocksize = network.get_layer(index=0).get_config()['batch_input_shape'][1:][1]                        \n",
    "            number_of_outputs = network.get_layer(index=-1).get_config()['units']\n",
    "            output_shape = (sample_size, number_of_outputs)\n",
    "            targets = np.zeros(output_shape)\n",
    "            \n",
    "            \n",
    "            batch_size = sample_size\n",
    "            trajectory, target, target_real = simulate_trajectory(batch_size)\n",
    "            #trajectory = trajectory.scaled_values\n",
    "            trajectory_dimensions = [sample_size, round(trajectory.size/network_blocksize/sample_size), network_blocksize]\n",
    "            trajectories = np.array(trajectory).reshape(trajectory_dimensions)\n",
    "            targets = target#.scaled_values\n",
    "                \n",
    "                \n",
    "\n",
    "            # training\n",
    "            history = network.fit(trajectories,\n",
    "                                targets,\n",
    "                                epochs=1, \n",
    "                                batch_size=sample_size,\n",
    "                                verbose=False)\n",
    "                        \n",
    "            # measure elapsed time during iteration\n",
    "            iteration_time = time() - initial_time\n",
    "\n",
    "            # record training history\n",
    "            mse = history.history['mse'][0]\n",
    "            mae = history.history['mae'][0]\n",
    "                        \n",
    "            training_history['Sample Size'].append(sample_size)\n",
    "            training_history['Iteration Number'].append(iteration)\n",
    "            training_history['Iteration Time'].append(iteration_time)\n",
    "            training_history['MSE'].append(mse)\n",
    "            training_history['MAE'].append(mae)\n",
    "\n",
    "            if not(iteration%int(verbose**-1)):\n",
    "                print('Sample size %6d   iteration number %6d   MSE %10.4f   MAE %10.4f   Time %10f ms' % (sample_size, iteration + 1, mse, mae, iteration_time * 1000))\n",
    "                \n",
    "    return training_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8778b2",
   "metadata": {},
   "source": [
    "##### PLOT THE PERFORMANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a67c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_performance(training_history, number_of_timesteps_for_average = 100, figsize=(20,20)):\n",
    "    \"\"\"Plot the learning performance of the deep learning network.\n",
    "    \n",
    "    Input:\n",
    "    training_history: dictionary with training history, typically obtained from train_deep_learning_network()\n",
    "    number_of_timesteps_for_average: length of the average [positive integer number]\n",
    "    figsize: figure size [list of two positive numbers]\n",
    "        \n",
    "    Output: none\n",
    "    \"\"\"    \n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from numpy import convolve, ones\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.subplot(5, 1, 1)\n",
    "    plt.semilogy(training_history['MSE'], 'k')\n",
    "    plt.semilogy(convolve(training_history['MSE'], ones(number_of_timesteps_for_average) / number_of_timesteps_for_average, mode='valid'), 'r')\n",
    "    plt.ylabel('MSE', fontsize=24)\n",
    "    plt.xlabel('Epochs', fontsize=24)\n",
    "\n",
    "    plt.subplot(5, 1, 2)\n",
    "    plt.semilogy(training_history['MAE'], 'k')\n",
    "    plt.semilogy(convolve(training_history['MAE'], ones(number_of_timesteps_for_average) / number_of_timesteps_for_average, mode='valid'), 'r')\n",
    "    plt.ylabel('MAE', fontsize=24)\n",
    "    plt.xlabel('Epochs', fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bda8119",
   "metadata": {},
   "source": [
    "##### TEST THE DNN ON NEW SIMULATED TRAJECTORIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1daf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network, trajectory):\n",
    "    \"\"\" Predict parameters of the force field from the trajectory using the deep learnign network.\n",
    "    \n",
    "    Inputs:\n",
    "    network: deep learning network\n",
    "    image: trajectroy [numpy array of real numbers]\n",
    "    \n",
    "    Output:\n",
    "    predicted_targets: predicted parameters of the calibrated force field [1D numpy array containing outputs]\n",
    "    \"\"\"\n",
    "    \n",
    "    from numpy import reshape\n",
    "    \n",
    "    network_blocksize = network.get_layer(index=0).get_config()['batch_input_shape'][1:][1]\n",
    "    predicted_targets = network.predict(reshape(trajectory, [1,round(trajectory.size/network_blocksize),network_blocksize]))   \n",
    "        \n",
    "    return predicted_targets\n",
    "\n",
    "\n",
    "def test_performance(simulate_trajectory, network, rescale_targets, number_of_predictions_to_show=100):#, dt = 1e-1):\n",
    "\n",
    "    \n",
    "    network_blocksize = network.get_layer(index=0).get_config()['batch_input_shape'][1:][1]\n",
    "\n",
    "\n",
    "    predictions_scaled = []\n",
    "    predictions_physical = []\n",
    "\n",
    "    batch_size = number_of_predictions_to_show\n",
    "    trajectory, targets, targets_real = simulate_trajectory(batch_size)\n",
    "    targets_physical = list(targets_real)#targets.values)\n",
    "    targets_scaled = list(targets)#.scaled_values)\n",
    "    #trajectory = trajectory.scaled_values\n",
    "    trajectory_dimensions = [number_of_predictions_to_show, round(trajectory.size/network_blocksize/number_of_predictions_to_show) , network_blocksize]\n",
    "    trajectories = np.array(trajectory).reshape(trajectory_dimensions)\n",
    "       \n",
    "\n",
    "    for i in range(number_of_predictions_to_show):\n",
    "        predictions = predict(network, trajectories[i])\n",
    "\n",
    "\n",
    "        predictions_scaled.append(predictions[0])\n",
    "        predictions_physical.append(rescale_targets(*predictions[0]))\n",
    "\n",
    "    number_of_outputs = network.get_layer(index=-1).get_config()['units']    \n",
    "\n",
    "    targets_physical = np.array(targets_physical).transpose()\n",
    "    targets_scaled = np.array(targets_scaled).transpose()\n",
    "    predictions_scaled = np.array(predictions_scaled).transpose()\n",
    "    predictions_physical = np.array(predictions_physical).transpose()\n",
    "\n",
    "    # Do not show results at the edges of the training range \n",
    "\n",
    "    if number_of_outputs>1:\n",
    "\n",
    "        ind = np.isfinite(targets_scaled[0])\n",
    "        for target_number in range(number_of_outputs):\n",
    "            target_max = .9 * np.max(targets_scaled[target_number]) + .1 * np.min(targets_scaled[target_number])\n",
    "            target_min = .1 * np.max(targets_scaled[target_number]) + .9 * np.min(targets_scaled[target_number])\n",
    "            ind = np.logical_and(ind, targets_scaled[target_number] < target_max)\n",
    "            ind = np.logical_and(ind, targets_scaled[target_number] > target_min)\n",
    "    else:\n",
    "        target_max = .9 * np.max(targets_scaled) + .1 * np.min(targets_scaled)\n",
    "        target_min = .1 * np.max(targets_scaled) + .9 * np.min(targets_scaled)\n",
    "        ind = np.logical_and(targets_scaled < target_max, targets_scaled > target_min)\n",
    "\n",
    "    return targets_scaled, targets_physical, predictions_scaled, predictions_physical\n",
    "\n",
    "\n",
    "def plot_test_performance(targets_scaled, targets_physical, predictions_scaled, predictions_physical, network):\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    #from . import predict\n",
    "\n",
    "    number_of_outputs = network.get_layer(index=-1).get_config()['units']    \n",
    "    \n",
    "    if number_of_outputs>1:\n",
    "\n",
    "        for target_number in range(number_of_outputs):\n",
    "            plt.figure(figsize=(20, 10))\n",
    "\n",
    "            plt.subplot(121)\n",
    "            plt.plot(targets_scaled[target_number],\n",
    "                     predictions_scaled[target_number],\n",
    "                     '.')\n",
    "            #plt.xlabel(targets.scalings[target_number], fontsize=18)\n",
    "            #plt.ylabel('Predicted ' + targets.scalings[target_number], fontsize=18)\n",
    "            plt.axis('square')\n",
    "            plt.title('Prediction performance in scaled units', fontsize=18)\n",
    "\n",
    "            plt.subplot(122)\n",
    "            plt.plot(targets_physical[target_number],\n",
    "                     predictions_physical[target_number],\n",
    "                    '.')\n",
    "            #plt.xlabel(targets.names[target_number], fontsize=18)\n",
    "            #plt.ylabel('Predicted ' + targets.names[target_number], fontsize=18)\n",
    "            plt.axis('square')\n",
    "            plt.title('Prediction performance in real units', fontsize=18)\n",
    "\n",
    "\n",
    "    else: \n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        plt.subplot(121)\n",
    "        plt.plot(targets_scaled[ind],\n",
    "                 predictions_scaled.transpose()[ind],\n",
    "                 '.')\n",
    "        #plt.xlabel(targets.scalings[0], fontsize=18)\n",
    "        #plt.ylabel('Predicted ' + targets.scalings[0], fontsize=18)\n",
    "        plt.axis('square')\n",
    "        plt.title('Prediction performance in scaled units', fontsize=18)\n",
    "\n",
    "        plt.subplot(122)\n",
    "        plt.plot(targets_physical[ind],\n",
    "                 predictions_physical.transpose()[ind],\n",
    "                '.')\n",
    "        #plt.xlabel(targets.names[0], fontsize=18)\n",
    "        #plt.ylabel('Predicted ' + targets.names[0], fontsize=18)\n",
    "        plt.axis('square')\n",
    "        plt.title('Prediction performance in real units', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8659ae50",
   "metadata": {},
   "source": [
    "## LSTM with ATTENTION\n",
    "\n",
    "CREATE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bebd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "import keras.backend as K\n",
    "\n",
    "# Add attention layer to the deep learning network\n",
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    " \n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name='attention_weight', shape=(input_shape[-1],1), \n",
    "                               initializer='random_normal', trainable=True)\n",
    "        self.b=self.add_weight(name='attention_bias', shape=(input_shape[1],1), \n",
    "                               initializer='zeros', trainable=True)        \n",
    "        super(attention, self).build(input_shape)\n",
    " \n",
    "    def call(self,x):\n",
    "        # Alignment scores. Pass them through tanh function\n",
    "        e = K.tanh(K.dot(x,self.W)+self.b)\n",
    "        # Remove dimension of size 1\n",
    "        e = K.squeeze(e, axis=-1)   \n",
    "        # Compute the weights\n",
    "        alpha = K.softmax(e)\n",
    "        # Reshape to tensorFlow format\n",
    "        alpha = K.expand_dims(alpha, axis=-1)\n",
    "        # Compute the context vector\n",
    "        context = x * alpha\n",
    "        context = K.sum(context, axis=1)\n",
    "        return context\n",
    "    \n",
    "\n",
    "def create_deep_learning_network_with_attention(\n",
    "    input_shape=(None, 50),\n",
    "    lstm_layers_dimensions=(100, 50),\n",
    "    number_of_outputs=2) :\n",
    "    \"\"\"Creates and compiles a deep learning network.\n",
    "    \n",
    "    Inputs:    \n",
    "    input_shape: Should be the same size of the input trajectory []\n",
    "    lstm_layers_dimensions: number of neurons in each LSTM layer [tuple of positive integers]\n",
    "        \n",
    "    Output:\n",
    "    network: deep learning network\n",
    "    \"\"\"    \n",
    "\n",
    "    from keras import models, layers, optimizers\n",
    "\n",
    "    ### ATTENTION LAYER\n",
    "    def attention_layer(inputs):\n",
    "        attention_units = K.int_shape(inputs)[-1]\n",
    "        attention_weights = layers.Dense(attention_units, activation='softmax')(inputs)\n",
    "        weighted_inputs = layers.Multiply()([inputs, attention_weights])\n",
    "        return weighted_inputs\n",
    "    \n",
    "    ### INITIALIZE DEEP LEARNING NETWORK\n",
    "    network = models.Sequential()\n",
    "\n",
    "    ### CONVOLUTIONAL BASIS\n",
    "    for lstm_layer_number, lstm_layer_dimension in zip(range(len(lstm_layers_dimensions)), lstm_layers_dimensions):\n",
    "\n",
    "        # add LSTM layer\n",
    "        lstm_layer_name = 'lstm_' + str(lstm_layer_number + 1)\n",
    "        if lstm_layer_number + 1 < len(lstm_layers_dimensions): # All layers but last\n",
    "            lstm_layer = layers.LSTM(lstm_layer_dimension,\n",
    "                                     return_sequences=True,\n",
    "                                     dropout=0,\n",
    "                                     recurrent_dropout=0,\n",
    "                                     input_shape=input_shape,\n",
    "                                     name=lstm_layer_name)\n",
    "\n",
    "        else: # Last layer\n",
    "            lstm_layer = layers.LSTM(lstm_layer_dimension,\n",
    "                                     return_sequences=False,\n",
    "                                     dropout=0,\n",
    "                                     recurrent_dropout=0,\n",
    "                                     input_shape=input_shape,\n",
    "                                     name=lstm_layer_name)\n",
    "\n",
    "        network.add(lstm_layer)\n",
    "    \n",
    "    # Add Attention Layer\n",
    "    attention_lay = attention()(network)\n",
    "    network.add(attention())\n",
    "\n",
    "    # OUTPUT LAYER\n",
    "    output_layer = layers.Dense(number_of_outputs, name='output')\n",
    "    network.add(output_layer)\n",
    "    \n",
    "    network.compile(optimizer=optimizers.Adam(lr=1e-3), loss='mse', metrics=['mse', 'mae'])\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bf2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create deep learning network\n",
    "networkLSTMwithATTENTION = create_deep_learning_network()\n",
    "\n",
    "### Print deep learning network summary\n",
    "networkLSTMwithATTENTION.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1275a65",
   "metadata": {},
   "source": [
    "#### TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "training_history_LSTM_attention = train_deep_learning_network(networkLSTMwithATTENTION, simulate_trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76f61b",
   "metadata": {},
   "source": [
    "#### TEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44118a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "number_of_predictions_to_show = 1000\n",
    "prediction_LSTMwithATTENTION_test = test_performance(simulate_trajectory, networkLSTMwithATTENTION, rescale_targets, number_of_predictions_to_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5720e775",
   "metadata": {},
   "source": [
    "#### Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fbd20",
   "metadata": {},
   "source": [
    "### Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f0a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot learning performance\n",
    "number_of_timesteps_for_average = 100\n",
    "plot_learning_performance(training_history_LSTM_attention, number_of_timesteps_for_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8db5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot test performance\n",
    "plot_test_performance(prediction_LSTMwithATTENTION_test[0], prediction_LSTMwithATTENTION_test[1], prediction_LSTMwithATTENTION_test[2], prediction_LSTMwithATTENTION_test[3], networkLSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
